{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399fbba",
   "metadata": {},
   "source": [
    "## 1. Load Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(agent_name, log_dir='../logs'):\n",
    "    \"\"\"Load training results from JSON file.\"\"\"\n",
    "    results_path = Path(log_dir) / agent_name / 'results.json'\n",
    "    \n",
    "    if results_path.exists():\n",
    "        with open(results_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        print(f\"Results not found: {results_path}\")\n",
    "        return None\n",
    "\n",
    "def load_tensorboard_data(agent_name, log_dir='../logs', tag='Episode/Score'):\n",
    "    \"\"\"Load episode scores from TensorBoard logs.\"\"\"\n",
    "    log_path = Path(log_dir) / agent_name\n",
    "    \n",
    "    if not log_path.exists():\n",
    "        print(f\"Log directory not found: {log_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Find event file\n",
    "    event_files = list(log_path.glob('events.out.tfevents.*'))\n",
    "    if not event_files:\n",
    "        print(f\"No TensorBoard event files found in {log_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load events\n",
    "    ea = event_accumulator.EventAccumulator(str(log_path))\n",
    "    ea.Reload()\n",
    "    \n",
    "    # Get scalar data\n",
    "    try:\n",
    "        events = ea.Scalars(tag)\n",
    "        steps = [e.step for e in events]\n",
    "        values = [e.value for e in events]\n",
    "        return steps, values\n",
    "    except KeyError:\n",
    "        print(f\"Tag '{tag}' not found in TensorBoard logs\")\n",
    "        return None, None\n",
    "\n",
    "# Load results for all agents\n",
    "agents = ['dqn', 'ppo', 'sac']\n",
    "results = {agent: load_results(agent) for agent in agents}\n",
    "\n",
    "# Display summary\n",
    "for agent, result in results.items():\n",
    "    if result:\n",
    "        print(f\"\\n{agent.upper()} Results:\")\n",
    "        print(f\"  Total Episodes: {result.get('total_episodes', 'N/A')}\")\n",
    "        print(f\"  Mean Score: {result.get('mean_score', 'N/A'):.2f}\")\n",
    "        print(f\"  Max Score: {result.get('max_score', 'N/A'):.2f}\")\n",
    "        print(f\"  Converged at Episode: {result.get('converged_episode', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e180f0a",
   "metadata": {},
   "source": [
    "## 2. Learning Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58131b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(agents, log_dir='../logs', window=50):\n",
    "    \"\"\"Plot learning curves for all agents.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    colors = {'dqn': 'blue', 'ppo': 'green', 'sac': 'red'}\n",
    "    \n",
    "    for agent in agents:\n",
    "        episodes, scores = load_tensorboard_data(agent, log_dir)\n",
    "        \n",
    "        if episodes is not None and scores is not None:\n",
    "            # Plot raw scores\n",
    "            ax1.plot(episodes, scores, alpha=0.3, color=colors[agent])\n",
    "            \n",
    "            # Calculate moving average\n",
    "            if len(scores) >= window:\n",
    "                moving_avg = pd.Series(scores).rolling(window=window).mean()\n",
    "                ax1.plot(episodes, moving_avg, label=agent.upper(), \n",
    "                        color=colors[agent], linewidth=2)\n",
    "            else:\n",
    "                ax1.plot(episodes, scores, label=agent.upper(), \n",
    "                        color=colors[agent], linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Episode')\n",
    "    ax1.set_ylabel('Episode Reward')\n",
    "    ax1.set_title('Learning Curves (Episode Rewards)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axhline(y=700, color='black', linestyle='--', label='Target Score (700)')\n",
    "    \n",
    "    # Plot only moving averages\n",
    "    for agent in agents:\n",
    "        episodes, scores = load_tensorboard_data(agent, log_dir)\n",
    "        \n",
    "        if episodes is not None and scores is not None:\n",
    "            if len(scores) >= window:\n",
    "                moving_avg = pd.Series(scores).rolling(window=window).mean()\n",
    "                ax2.plot(episodes, moving_avg, label=agent.upper(), \n",
    "                        color=colors[agent], linewidth=2)\n",
    "    \n",
    "    ax2.set_xlabel('Episode')\n",
    "    ax2.set_ylabel(f'Moving Average ({window} episodes)')\n",
    "    ax2.set_title(f'Smoothed Learning Curves')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.axhline(y=700, color='black', linestyle='--', label='Target Score (700)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../logs/learning_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e2711",
   "metadata": {},
   "source": [
    "## 3. Sample Efficiency Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_efficiency(agents, results):\n",
    "    \"\"\"Plot sample efficiency comparison.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    agent_names = []\n",
    "    converged_episodes = []\n",
    "    final_scores = []\n",
    "    \n",
    "    for agent in agents:\n",
    "        if results[agent]:\n",
    "            agent_names.append(agent.upper())\n",
    "            conv_ep = results[agent].get('converged_episode')\n",
    "            converged_episodes.append(conv_ep if conv_ep else results[agent]['total_episodes'])\n",
    "            final_scores.append(results[agent].get('recent_mean', results[agent]['mean_score']))\n",
    "    \n",
    "    # Create bar plot\n",
    "    x = np.arange(len(agent_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, converged_episodes, width, label='Episodes to Convergence', \n",
    "           color=['blue', 'green', 'red'], alpha=0.7)\n",
    "    ax.bar(x + width/2, final_scores, width, label='Final Average Score', \n",
    "           color=['lightblue', 'lightgreen', 'lightcoral'], alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Agent')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Sample Efficiency and Final Performance')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(agent_names)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../logs/sample_efficiency_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_efficiency(agents, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afab88d",
   "metadata": {},
   "source": [
    "## 4. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e24156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(agents, results):\n",
    "    \"\"\"Create summary statistics table.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for agent in agents:\n",
    "        if results[agent]:\n",
    "            r = results[agent]\n",
    "            data.append({\n",
    "                'Agent': agent.upper(),\n",
    "                'Total Episodes': r.get('total_episodes', 'N/A'),\n",
    "                'Mean Score': f\"{r.get('mean_score', 0):.2f}\",\n",
    "                'Std Score': f\"{r.get('std_score', 0):.2f}\",\n",
    "                'Min Score': f\"{r.get('min_score', 0):.2f}\",\n",
    "                'Max Score': f\"{r.get('max_score', 0):.2f}\",\n",
    "                'Recent Mean': f\"{r.get('recent_mean', 0):.2f}\",\n",
    "                'Recent Std': f\"{r.get('recent_std', 0):.2f}\",\n",
    "                'Converged Episode': r.get('converged_episode', 'N/A')\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "summary_df = create_summary_table(agents, results)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"AGENT COMPARISON SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "# Save to CSV\n",
    "summary_df.to_csv('../logs/comparison_summary.csv', index=False)\n",
    "print(\"Summary saved to: logs/comparison_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66e7645",
   "metadata": {},
   "source": [
    "## 5. Box Plot Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_distributions(agents, log_dir='../logs'):\n",
    "    \"\"\"Plot score distributions for all agents.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for agent in agents:\n",
    "        _, scores = load_tensorboard_data(agent, log_dir)\n",
    "        if scores:\n",
    "            # Use last 100 episodes for distribution\n",
    "            data.append(scores[-100:])\n",
    "            labels.append(agent.upper())\n",
    "    \n",
    "    bp = ax.boxplot(data, labels=labels, patch_artist=True)\n",
    "    \n",
    "    # Color boxes\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax.set_ylabel('Episode Reward')\n",
    "    ax.set_title('Score Distribution (Last 100 Episodes)')\n",
    "    ax.axhline(y=700, color='red', linestyle='--', label='Target Score (700)', alpha=0.5)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../logs/score_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_score_distributions(agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda36e4",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Sample Efficiency**: Compare which agent reached the target score (700) fastest\n",
    "2. **Final Performance**: Compare the final average scores across agents\n",
    "3. **Stability**: Compare variance in episode rewards (lower is better)\n",
    "4. **Action Space**: DQN uses discrete actions while PPO/SAC use continuous actions\n",
    "\n",
    "### Expected Results:\n",
    "- **DQN**: Typically achieves 700-850 scores but may be less sample-efficient\n",
    "- **PPO**: Good balance of sample efficiency and final performance\n",
    "- **SAC**: Often most sample-efficient with continuous actions, typically achieves 850-950\n",
    "\n",
    "### Recommendations:\n",
    "- For deployment: Choose the agent with best final performance and stability\n",
    "- For sample efficiency: Choose the agent that converges fastest\n",
    "- For continuous control: PPO or SAC are more suitable than DQN"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
